
Model name: google/gemma-2-27b

Loading checkpoint shards:   0%|          | 0/24 [00:00<?, ?it/s]Loading checkpoint shards:   4%|▍         | 1/24 [00:03<01:27,  3.82s/it]Loading checkpoint shards:   8%|▊         | 2/24 [00:07<01:20,  3.64s/it]Loading checkpoint shards:  12%|█▎        | 3/24 [00:11<01:23,  3.96s/it]Loading checkpoint shards:  17%|█▋        | 4/24 [00:15<01:21,  4.06s/it]Loading checkpoint shards:  21%|██        | 5/24 [00:19<01:15,  3.96s/it]Loading checkpoint shards:  25%|██▌       | 6/24 [00:24<01:15,  4.19s/it]Loading checkpoint shards:  29%|██▉       | 7/24 [00:28<01:11,  4.21s/it]Loading checkpoint shards:  29%|██▉       | 7/24 [00:29<01:11,  4.20s/it]
Traceback (most recent call last):
  File "/home/ych22001/LLM/LLM_ALFWorld/ALFWorld_test/ALFW_google_gemma-2-27b.py", line 41, in <module>
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/ych22001/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/ych22001/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3838, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/ych22001/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 4298, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/home/ych22001/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 895, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/home/ych22001/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 400, in set_module_tensor_to_device
    new_value = value.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 324.00 MiB. GPU 
